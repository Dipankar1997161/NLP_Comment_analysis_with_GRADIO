{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2b77b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37feb340",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-15 17:06:26.817267: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-15 17:06:26.817569: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-15 17:06:26.832883: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-15 17:06:26.833138: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-15 17:06:26.833306: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-15 17:06:26.833460: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "#setup GPU\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "#gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "#if gpus:\n",
    "#    try:\n",
    "#        # Currently, memory growth needs to be the same across GPUs\n",
    "#       for gpu in gpus:\n",
    "#            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "#        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "#        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "#    except RuntimeError as e:\n",
    "#        # Memory growth must be set before GPUs have been initialized\n",
    "#        print(e)\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f8686a",
   "metadata": {},
   "source": [
    "### Explore / Analyse data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a634a16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159566</th>\n",
       "      <td>ffe987279560d7ff</td>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159567</th>\n",
       "      <td>ffea4adeee384e90</td>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159568</th>\n",
       "      <td>ffee36eab5c267c9</td>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159569</th>\n",
       "      <td>fff125370e4aaaf3</td>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159570</th>\n",
       "      <td>fff46fc426af1f9a</td>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159571 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                       comment_text  \\\n",
       "0       0000997932d777bf  Explanation\\nWhy the edits made under my usern...   \n",
       "1       000103f0d9cfb60f  D'aww! He matches this background colour I'm s...   \n",
       "2       000113f07ec002fd  Hey man, I'm really not trying to edit war. It...   \n",
       "3       0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...   \n",
       "4       0001d958c54c6e35  You, sir, are my hero. Any chance you remember...   \n",
       "...                  ...                                                ...   \n",
       "159566  ffe987279560d7ff  \":::::And for the second time of asking, when ...   \n",
       "159567  ffea4adeee384e90  You should be ashamed of yourself \\n\\nThat is ...   \n",
       "159568  ffee36eab5c267c9  Spitzer \\n\\nUmm, theres no actual article for ...   \n",
       "159569  fff125370e4aaaf3  And it looks like it was actually you who put ...   \n",
       "159570  fff46fc426af1f9a  \"\\nAnd ... I really don't think you understand...   \n",
       "\n",
       "        toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0           0             0        0       0       0              0  \n",
       "1           0             0        0       0       0              0  \n",
       "2           0             0        0       0       0              0  \n",
       "3           0             0        0       0       0              0  \n",
       "4           0             0        0       0       0              0  \n",
       "...       ...           ...      ...     ...     ...            ...  \n",
       "159566      0             0        0       0       0              0  \n",
       "159567      0             0        0       0       0              0  \n",
       "159568      0             0        0       0       0              0  \n",
       "159569      0             0        0       0       0              0  \n",
       "159570      0             0        0       0       0              0  \n",
       "\n",
       "[159571 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading files\n",
    "\n",
    "train_data = pd.read_csv(\"data/train.csv\")\n",
    "train_data\n",
    "\n",
    "# the column is not being displayed totally, so we will increase the width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78ac8232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.iloc[2]['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34deb4c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toxic            0\n",
       "severe_toxic     0\n",
       "obscene          0\n",
       "threat           0\n",
       "insult           0\n",
       "identity_hate    0\n",
       "Name: 2, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[train_data.columns[2:]].iloc[2]\n",
    "\n",
    "# This shows that the following comment is not toxic at all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "727347ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display full comment by increasing the column width using pandas\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "872be2ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\"  -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know.\\n\\nThere appears to be a backlog on articles for review so I guess there may be a delay until a reviewer turns up. It's listed in the relevant form eg Wikipedia:Good_article_nominations#Transport  \"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember what page that's on?</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159566</th>\n",
       "      <td>ffe987279560d7ff</td>\n",
       "      <td>\":::::And for the second time of asking, when your view completely contradicts the coverage in reliable sources, why should anyone care what you feel? You can't even give a consistent argument - is the opening only supposed to mention significant aspects, or the \"\"most significant\"\" ones?   \\n\\n\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159567</th>\n",
       "      <td>ffea4adeee384e90</td>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is a horrible thing you put on my talk page.  128.61.19.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159568</th>\n",
       "      <td>ffee36eab5c267c9</td>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for prostitution ring.  - Crunch Captain.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159569</th>\n",
       "      <td>fff125370e4aaaf3</td>\n",
       "      <td>And it looks like it was actually you who put on the speedy to have the first version deleted now that I look at it.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159570</th>\n",
       "      <td>fff46fc426af1f9a</td>\n",
       "      <td>\"\\nAnd ... I really don't think you understand.  I came here and my idea was bad right away.  What kind of community goes \"\"you have bad ideas\"\" go away, instead of helping rewrite them.   \"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159571 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id  \\\n",
       "0       0000997932d777bf   \n",
       "1       000103f0d9cfb60f   \n",
       "2       000113f07ec002fd   \n",
       "3       0001b41b1c6bb37e   \n",
       "4       0001d958c54c6e35   \n",
       "...                  ...   \n",
       "159566  ffe987279560d7ff   \n",
       "159567  ffea4adeee384e90   \n",
       "159568  ffee36eab5c267c9   \n",
       "159569  fff125370e4aaaf3   \n",
       "159570  fff46fc426af1f9a   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              comment_text  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.   \n",
       "3       \"\\nMore\\nI can't make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\"  -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know.\\n\\nThere appears to be a backlog on articles for review so I guess there may be a delay until a reviewer turns up. It's listed in the relevant form eg Wikipedia:Good_article_nominations#Transport  \"   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      You, sir, are my hero. Any chance you remember what page that's on?   \n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    ...   \n",
       "159566                                                                                                                                                                                                                                                                                                                                           \":::::And for the second time of asking, when your view completely contradicts the coverage in reliable sources, why should anyone care what you feel? You can't even give a consistent argument - is the opening only supposed to mention significant aspects, or the \"\"most significant\"\" ones?   \\n\\n\"   \n",
       "159567                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               You should be ashamed of yourself \\n\\nThat is a horrible thing you put on my talk page.  128.61.19.93   \n",
       "159568                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Spitzer \\n\\nUmm, theres no actual article for prostitution ring.  - Crunch Captain.   \n",
       "159569                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                And it looks like it was actually you who put on the speedy to have the first version deleted now that I look at it.   \n",
       "159570                                                                                                                                                                                                                                                                                                                                                                                                                                                      \"\\nAnd ... I really don't think you understand.  I came here and my idea was bad right away.  What kind of community goes \"\"you have bad ideas\"\" go away, instead of helping rewrite them.   \"   \n",
       "\n",
       "        toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0           0             0        0       0       0              0  \n",
       "1           0             0        0       0       0              0  \n",
       "2           0             0        0       0       0              0  \n",
       "3           0             0        0       0       0              0  \n",
       "4           0             0        0       0       0              0  \n",
       "...       ...           ...      ...     ...     ...            ...  \n",
       "159566      0             0        0       0       0              0  \n",
       "159567      0             0        0       0       0              0  \n",
       "159568      0             0        0       0       0              0  \n",
       "159569      0             0        0       0       0              0  \n",
       "159570      0             0        0       0       0              0  \n",
       "\n",
       "[159571 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#recheck the data with increased column width\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64608611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count   Dtype \n",
      "---  ------         --------------   ----- \n",
      " 0   id             159571 non-null  object\n",
      " 1   comment_text   159571 non-null  object\n",
      " 2   toxic          159571 non-null  int64 \n",
      " 3   severe_toxic   159571 non-null  int64 \n",
      " 4   obscene        159571 non-null  int64 \n",
      " 5   threat         159571 non-null  int64 \n",
      " 6   insult         159571 non-null  int64 \n",
      " 7   identity_hate  159571 non-null  int64 \n",
      "dtypes: int64(6), object(2)\n",
      "memory usage: 9.7+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.095844</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>0.052948</td>\n",
       "      <td>0.002996</td>\n",
       "      <td>0.049364</td>\n",
       "      <td>0.008805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.294379</td>\n",
       "      <td>0.099477</td>\n",
       "      <td>0.223931</td>\n",
       "      <td>0.054650</td>\n",
       "      <td>0.216627</td>\n",
       "      <td>0.093420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               toxic   severe_toxic        obscene         threat  \\\n",
       "count  159571.000000  159571.000000  159571.000000  159571.000000   \n",
       "mean        0.095844       0.009996       0.052948       0.002996   \n",
       "std         0.294379       0.099477       0.223931       0.054650   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "              insult  identity_hate  \n",
       "count  159571.000000  159571.000000  \n",
       "mean        0.049364       0.008805  \n",
       "std         0.216627       0.093420  \n",
       "min         0.000000       0.000000  \n",
       "25%         0.000000       0.000000  \n",
       "50%         0.000000       0.000000  \n",
       "75%         0.000000       0.000000  \n",
       "max         1.000000       1.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#retrieve the information\n",
    "train_data.info()\n",
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a728d09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0002bcb3da6cb337</td>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0005c987bdfc9d4b</td>\n",
       "      <td>Hey... what is it..\\n@ | talk .\\nWhat is it... an exclusive group of some WP TALIBANS...who are good at destroying, self-appointed purist who GANG UP any one who asks them questions abt their ANTI-SOCIAL and DESTRUCTIVE (non)-contribution at WP?\\n\\nAsk Sityush to clean up his behavior than issue me nonsensical warnings...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0007e25b2121310b</td>\n",
       "      <td>Bye! \\n\\nDon't look, come or think of comming back! Tosser.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>001810bf8c45bf5f</td>\n",
       "      <td>You are gay or antisemmitian? \\n\\nArchangel WHite Tiger\\n\\nMeow! Greetingshhh!\\n\\nUh, there are two ways, why you do erased my comment about WW2, that holocaust was brutally slaying of Jews and not gays/Gypsys/Slavs/anyone...\\n\\n1 - If you are anti-semitian, than shave your head bald and go to the skinhead meetings!\\n\\n2 - If you doubt words of the Bible, that homosexuality is a deadly sin, make a pentagram tatoo on your forehead go to the satanistic masses with your gay pals!\\n\\n3 - First and last warning, you fucking gay - I won't appreciate if any more nazi shwain would write in my page! I don't wish to talk to you anymore!\\n\\nBeware of the Dark Side!</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>00190820581d90ce</td>\n",
       "      <td>FUCK YOUR FILTHY MOTHER IN THE ASS, DRY!</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id  \\\n",
       "6   0002bcb3da6cb337   \n",
       "12  0005c987bdfc9d4b   \n",
       "16  0007e25b2121310b   \n",
       "42  001810bf8c45bf5f   \n",
       "43  00190820581d90ce   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              comment_text  \\\n",
       "6                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK   \n",
       "12                                                                                                                                                                                                                                                                                                                                                     Hey... what is it..\\n@ | talk .\\nWhat is it... an exclusive group of some WP TALIBANS...who are good at destroying, self-appointed purist who GANG UP any one who asks them questions abt their ANTI-SOCIAL and DESTRUCTIVE (non)-contribution at WP?\\n\\nAsk Sityush to clean up his behavior than issue me nonsensical warnings...   \n",
       "16                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Bye! \\n\\nDon't look, come or think of comming back! Tosser.   \n",
       "42  You are gay or antisemmitian? \\n\\nArchangel WHite Tiger\\n\\nMeow! Greetingshhh!\\n\\nUh, there are two ways, why you do erased my comment about WW2, that holocaust was brutally slaying of Jews and not gays/Gypsys/Slavs/anyone...\\n\\n1 - If you are anti-semitian, than shave your head bald and go to the skinhead meetings!\\n\\n2 - If you doubt words of the Bible, that homosexuality is a deadly sin, make a pentagram tatoo on your forehead go to the satanistic masses with your gay pals!\\n\\n3 - First and last warning, you fucking gay - I won't appreciate if any more nazi shwain would write in my page! I don't wish to talk to you anymore!\\n\\nBeware of the Dark Side!   \n",
       "43                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                FUCK YOUR FILTHY MOTHER IN THE ASS, DRY!   \n",
       "\n",
       "    toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "6       1             1        1       0       1              0  \n",
       "12      1             0        0       0       0              0  \n",
       "16      1             0        0       0       0              0  \n",
       "42      1             0        1       0       1              1  \n",
       "43      1             0        1       0       1              0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now lets check first 5 data with toxic or hate comments and LAUGH a BIT haha\n",
    "train_data[train_data['toxic'] == 1].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "249842e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61030</th>\n",
       "      <td>a36aa631f4e33bc7</td>\n",
       "      <td>\"\\n\\n HE BELIEVES IN OPENNESS BUT CLOSES HIS PAGE - BULL$HIT WE ALL SEE THRU U JIMBO \\n\\nWikipedia Founder Hit With Relationship Trouble, Allegations of Excessive Spending\\nBy Megan McCarthy March 03, 2008 | 3:34:58 PMCategories: People  \\nWikipedia founder Jimmy Wales didn't have such a good weekend. First the blogosphere and then Wikipedia itself lit up with news of his messy breakup with controversial Canadian TV pundit Rachel Marsden. Now, accusations are flying that Wales has been living the high life on the expense account of the nonprofit foundation he created.\\nOn Friday, reports surfaced that the married-but-divorcing Internet icon carried on a clandestine affair with Marsden.  Evidence of the affair included lurid IM transcripts, which appeared on Silicon Valley gossip blog Valleywag. On Saturday, Wales posted a statement on the Wikipedia Foundations website (which he later moved to his personal site) denying that his actions went against Wikimedia Foundation's policies, and stating that the affair had ended. Marsden responded by listing the clothes that he left at her house up for auction on eBay.\\nSo, what's the big deal when a relationship goes sour? Well, the two met when Marsden contacted Wales to help her \"\"clean up\"\" what she perceived to be errors on her personal Wikipedia page, and there have been allegations that Wales used his influence to improperly make changes.\\nFormer associates of Wales' are using this scandal to bring up other worries they have about the organization of the foundation. Former Wikimedia exec Danny Wool, who left the foundation last year, wrote a blog post insinuating that Wales used the non-profit foundation as his own personal piggy bank. Expenses that Wales tried to apply to the foundation included $300+ bottles of wine and visits to Moscow massage parlors, Wool alleges. According to Wool, the expenses got so out of hand that the Wikimedia foundation took away Wales' corporate credit card.\\n\"\"There were occasions where he used [the Wikimedia Foundation] for personal advancement under the guide of the mission.  And, as someone who was in there for the mission part of it, I found that rather distressful,\"\" Wool told EPICENTER.\\nWales did not immediately respond to a request for comment.\"</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22408</th>\n",
       "      <td>3b2609a95a16468e</td>\n",
       "      <td>bitches like donner60 like to feed on souls-bitch</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73107</th>\n",
       "      <td>c39272e03b4d2812</td>\n",
       "      <td>hi \\n\\ni wanna suck ur cock )</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4888</th>\n",
       "      <td>0cf27594013bb708</td>\n",
       "      <td>\"\\n Ain't bothering me, I'm not required to sign my posts/edit. I didn't specifically threaten anyone and your blowing it out of control. It was a snide comment. If I said \"\"I'm going to kill him in a fire\"\" thats different; saying \"\"I'm going to church to pray that he gets cancer or dies in a fire\"\" is more of a sarchastic tone. Pity you can't see that. No matter. Bump it up to 2 weeks now, just cause you can. \"</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134599</th>\n",
       "      <td>cfd580281d70d6ee</td>\n",
       "      <td>Are you gonna cry and tell wikipedia? Suck it up loser.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id  \\\n",
       "61030   a36aa631f4e33bc7   \n",
       "22408   3b2609a95a16468e   \n",
       "73107   c39272e03b4d2812   \n",
       "4888    0cf27594013bb708   \n",
       "134599  cfd580281d70d6ee   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         comment_text  \\\n",
       "61030   \"\\n\\n HE BELIEVES IN OPENNESS BUT CLOSES HIS PAGE - BULL$HIT WE ALL SEE THRU U JIMBO \\n\\nWikipedia Founder Hit With Relationship Trouble, Allegations of Excessive Spending\\nBy Megan McCarthy March 03, 2008 | 3:34:58 PMCategories: People  \\nWikipedia founder Jimmy Wales didn't have such a good weekend. First the blogosphere and then Wikipedia itself lit up with news of his messy breakup with controversial Canadian TV pundit Rachel Marsden. Now, accusations are flying that Wales has been living the high life on the expense account of the nonprofit foundation he created.\\nOn Friday, reports surfaced that the married-but-divorcing Internet icon carried on a clandestine affair with Marsden.  Evidence of the affair included lurid IM transcripts, which appeared on Silicon Valley gossip blog Valleywag. On Saturday, Wales posted a statement on the Wikipedia Foundations website (which he later moved to his personal site) denying that his actions went against Wikimedia Foundation's policies, and stating that the affair had ended. Marsden responded by listing the clothes that he left at her house up for auction on eBay.\\nSo, what's the big deal when a relationship goes sour? Well, the two met when Marsden contacted Wales to help her \"\"clean up\"\" what she perceived to be errors on her personal Wikipedia page, and there have been allegations that Wales used his influence to improperly make changes.\\nFormer associates of Wales' are using this scandal to bring up other worries they have about the organization of the foundation. Former Wikimedia exec Danny Wool, who left the foundation last year, wrote a blog post insinuating that Wales used the non-profit foundation as his own personal piggy bank. Expenses that Wales tried to apply to the foundation included $300+ bottles of wine and visits to Moscow massage parlors, Wool alleges. According to Wool, the expenses got so out of hand that the Wikimedia foundation took away Wales' corporate credit card.\\n\"\"There were occasions where he used [the Wikimedia Foundation] for personal advancement under the guide of the mission.  And, as someone who was in there for the mission part of it, I found that rather distressful,\"\" Wool told EPICENTER.\\nWales did not immediately respond to a request for comment.\"   \n",
       "22408                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               bitches like donner60 like to feed on souls-bitch   \n",
       "73107                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   hi \\n\\ni wanna suck ur cock )   \n",
       "4888                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \"\\n Ain't bothering me, I'm not required to sign my posts/edit. I didn't specifically threaten anyone and your blowing it out of control. It was a snide comment. If I said \"\"I'm going to kill him in a fire\"\" thats different; saying \"\"I'm going to church to pray that he gets cancer or dies in a fire\"\" is more of a sarchastic tone. Pity you can't see that. No matter. Bump it up to 2 weeks now, just cause you can. \"   \n",
       "134599                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Are you gonna cry and tell wikipedia? Suck it up loser.   \n",
       "\n",
       "        toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "61030       1             0        1       0       0              0  \n",
       "22408       1             0        1       0       1              0  \n",
       "73107       1             0        1       0       0              0  \n",
       "4888        1             0        0       1       0              0  \n",
       "134599      1             0        1       0       1              0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#random sampling using pd.sample(n, frac,....)\n",
    "train_data[train_data['toxic'] == 1].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3072c545",
   "metadata": {},
   "source": [
    "### Process the Data using Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bae9f817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using textvectorization for natural language, otherwise for normal string, use StringLookup\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "\n",
    "TextVectorization??\n",
    "\n",
    "#This layer has basic options for managing text in a Keras model. It transforms\n",
    "#a batch of strings (one example = one string) into either a list of token\n",
    "#indices (one example = 1D tensor of integer token indices) or a dense\n",
    "#representation (one example = 1D tensor of float values representing data\n",
    "#about the example's tokens). This layer is meant to handle natural language\n",
    "#inputs. To handle simple string inputs (categorical strings or pre-tokenized\n",
    "#strings) see `tf.keras.layers.StringLookup`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ca622db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                                                                                                                                                                                                                                                                                                                                                  Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)\n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                  Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.\n",
       "3         \"\\nMore\\nI can't make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\"  -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know.\\n\\nThere appears to be a backlog on articles for review so I guess there may be a delay until a reviewer turns up. It's listed in the relevant form eg Wikipedia:Good_article_nominations#Transport  \"\n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        You, sir, are my hero. Any chance you remember what page that's on?\n",
       "                                                                                                                                                                                                                                                                                                                                 ...                                                                                                                                                                                                                                                                                                                        \n",
       "159566                                                                                                                                                                                                                                                                                                                                             \":::::And for the second time of asking, when your view completely contradicts the coverage in reliable sources, why should anyone care what you feel? You can't even give a consistent argument - is the opening only supposed to mention significant aspects, or the \"\"most significant\"\" ones?   \\n\\n\"\n",
       "159567                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 You should be ashamed of yourself \\n\\nThat is a horrible thing you put on my talk page.  128.61.19.93\n",
       "159568                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Spitzer \\n\\nUmm, theres no actual article for prostitution ring.  - Crunch Captain.\n",
       "159569                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  And it looks like it was actually you who put on the speedy to have the first version deleted now that I look at it.\n",
       "159570                                                                                                                                                                                                                                                                                                                                                                                                                                                        \"\\nAnd ... I really don't think you understand.  I came here and my idea was bad right away.  What kind of community goes \"\"you have bad ideas\"\" go away, instead of helping rewrite them.   \"\n",
       "Name: comment_text, Length: 159571, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train_data['comment_text'] # comments\n",
    "y = train_data[train_data.columns[2:]].values #Features\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71b4d73c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y #numpy arrays to be passed onto the model for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5fb91c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying number of words for vectorization\n",
    "MAX_FEATURES = 200000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67d16691",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-15 17:07:09.367730: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-15 17:07:09.478084: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-15 17:07:09.478281: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-15 17:07:09.478431: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-15 17:07:09.478569: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-15 17:07:09.478705: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-15 17:07:09.478841: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-15 17:07:10.151149: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-15 17:07:10.151378: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-15 17:07:10.151528: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-15 17:07:10.151672: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-15 17:07:10.151813: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-15 17:07:10.151950: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7026 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2023-03-15 17:07:10.152554: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-15 17:07:10.152696: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 23386 MB memory:  -> device: 1, name: Quadro P6000, pci bus id: 0000:02:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "vectorize = TextVectorization(max_tokens = MAX_FEATURES, output_mode = 'int', output_sequence_length = 1800)\n",
    "\n",
    "#inputs(total number of words, output_type, max input length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "126f2157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00aae7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize.adapt(X.values) # passing the comments as numpy array to the model using X.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f620577c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '[UNK]', 'the', 'to', 'of', 'and', 'a', 'you', 'i', 'is', 'that', 'in', 'it', 'for', 'this', 'not', 'on', 'be', 'as', 'have', 'are', 'your', 'with', 'if', 'article', 'was', 'or', 'but', 'page', 'my', 'an', 'from', 'by', 'do', 'at', 'about', 'me', 'so', 'wikipedia', 'can', 'what', 'there', 'all', 'has', 'will', 'talk', 'please', 'would', 'its', 'no']\n"
     ]
    }
   ],
   "source": [
    "# lets check the first 50 generated vocabs from the Text vectorization\n",
    "print(vectorize.get_vocabulary()[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db60df83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=int64, numpy=array([520,  40,  20,   7, 273])>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# basic data_test to check the location in the vector\n",
    "vectorize(\"Nice, what are you doing?\")[:5]\n",
    "\n",
    "#check the 20th word in the upper section \"are\", the following is stored in the Tensor dsiplayed below \n",
    "#\"520,40, 20, 7, 273\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f890452",
   "metadata": {},
   "source": [
    "### Creating the data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e8bd3365",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-15 17:07:24.393690: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 2297822400 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(159571, 1800), dtype=int64, numpy=\n",
       "array([[  645,    76,     2, ...,     0,     0,     0],\n",
       "       [    1,    54,  2489, ...,     0,     0,     0],\n",
       "       [  425,   441,    70, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [32445,  7392,   383, ...,     0,     0,     0],\n",
       "       [    5,    12,   534, ...,     0,     0,     0],\n",
       "       [    5,     8,   130, ...,     0,     0,     0]])>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now vrctorizing the entire X values\n",
    "Vector_text = vectorize(X.values)\n",
    "Vector_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4ffb136e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=(TensorSpec(shape=(None, 1800), dtype=tf.int64, name=None), TensorSpec(shape=(None, 6), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pre-shuffle the data and setting the batch size for training\n",
    "\n",
    "#MCSHBAP - map, cache, shuffle, batch, prefetch from tensor_slices, list_files -> instantiating the data pipeline\n",
    "data = tf.data.Dataset.from_tensor_slices((Vector_text, y))\n",
    "data = data.cache()\n",
    "data = data.shuffle(160000)\n",
    "data = data.batch(24)\n",
    "data = data.prefetch(8) # helps prevent bottlenecks\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b05febc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-15 17:08:00.863077: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 2297822400 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[  328,    66,    14, ...,     0,     0,     0],\n",
       "        [   14,    42,   755, ...,     0,     0,     0],\n",
       "        [  248,   111,     4, ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [   23,    14,     9, ...,     0,     0,     0],\n",
       "        [  544,  8105, 52352, ...,     0,     0,     0],\n",
       "        [ 3429,     4,  2817, ...,     0,     0,     0]]),\n",
       " array([[0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0]]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.as_numpy_iterator().next()\n",
    "# first array is text in vectorized format.\n",
    "# 2nd array are the labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "51e48cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-15 17:08:04.166074: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 2297822400 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "X_batch, Y_batch = data.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e97a7b4",
   "metadata": {},
   "source": [
    "### Split data into train, test, split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9229d8df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4654"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(len(data)*.7) # partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c7c006d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 1800) (24, 6)\n",
      "The training sample is 4654, Valid Samples is 1329, Test Set is 664\n"
     ]
    }
   ],
   "source": [
    "print(X_batch.shape, Y_batch.shape)\n",
    "\n",
    "# 70%\n",
    "train = data.take(int(len(data)* .7))\n",
    "valid = data.skip(int(len(data)* .7)).take(int(len(data)* .2))\n",
    "test = data.skip(int(len(data)* .7)).skip(int(len(data)* .2)).take(int(len(data)* .1))\n",
    "\n",
    "print(f'The training sample is {len(train)}, Valid Samples is {len(valid)}, Test Set is {len(test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "736d2802",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-15 17:08:12.961095: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 2297822400 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train.as_numpy_iterator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "59f38cc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[  972, 18576,     8, ...,     0,     0,     0],\n",
       "        [    8,    47,    19, ...,     0,     0,     0],\n",
       "        [   94,    66,     3, ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [   49,   385,     4, ...,     0,     0,     0],\n",
       "        [   21,   126,    28, ...,     0,     0,     0],\n",
       "        [  358,     2,  4095, ...,     0,     0,     0]]),\n",
       " array([[0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0]]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.next() # use this to see how the model learns batchwiswe (run again and again)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db6a2db",
   "metadata": {},
   "source": [
    "##  HOW IT WORKS:\n",
    "Go through a batch -> forward pass -> backward pass -> update the gradients -> next batch [.next()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b88b1f",
   "metadata": {},
   "source": [
    "## Build Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2944f97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Bidirectional, Dense, Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c19b4f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictor():\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(MAX_FEATURES+1, 32, input_length = 1800))\n",
    "    \n",
    "    #GPU acceleration needed for LSTM layer should be tanh, defined by TENSORFLOW!!\n",
    "    model.add(Bidirectional(LSTM(32, activation = 'tanh'))) \n",
    "    # Bidirectional useful for NLP task for passing information both ways\n",
    "    \n",
    "    model.add(Dense(64, activation = 'elu'))\n",
    "    model.add(Dense(128, activation = 'elu'))\n",
    "    model.add(Dense(256, activation = 'elu'))\n",
    "    model.add(Dense(128, activation = 'elu'))\n",
    "    \n",
    "    #final_layer (24, 1800) (24, 6) -> the number of output as labels \"toxic, sever_toxic,.......\"\n",
    "    model.add(Dense(6, activation = 'sigmoid'))\n",
    "    model.compile(loss= 'BinaryCrossentropy', optimizer= 'Adam', metrics = ['acc'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9c7ec64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 1800, 32)          6400032   \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 64)               16640     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,495,846\n",
      "Trainable params: 6,495,846\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = predictor()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1612590a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
      "INFO:tensorflow:Single-worker MultiWorkerMirroredStrategy with local_devices = ('/device:GPU:0', '/device:GPU:1'), communication = CommunicationImplementation.AUTO\n"
     ]
    }
   ],
   "source": [
    "#mirrored_strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\"])\n",
    "#mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "strategy = tf.distribute.MultiWorkerMirroredStrategy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e89242ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a230d8b8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-15 11:14:35.257405: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4654/4654 [==============================] - 349s 74ms/step - loss: 0.0625 - acc: 0.9749 - val_loss: 0.0481 - val_acc: 0.5746\n",
      "Epoch 2/8\n",
      "4654/4654 [==============================] - 352s 76ms/step - loss: 0.0457 - acc: 0.9835 - val_loss: 0.0404 - val_acc: 0.9915\n",
      "Epoch 3/8\n",
      "4654/4654 [==============================] - 355s 76ms/step - loss: 0.0406 - acc: 0.9629 - val_loss: 0.0343 - val_acc: 0.9905\n",
      "Epoch 4/8\n",
      "4654/4654 [==============================] - 355s 76ms/step - loss: 0.0359 - acc: 0.9509 - val_loss: 0.0313 - val_acc: 0.9778\n",
      "Epoch 5/8\n",
      "4654/4654 [==============================] - 358s 77ms/step - loss: 0.0320 - acc: 0.9411 - val_loss: 0.0286 - val_acc: 0.9923\n",
      "Epoch 6/8\n",
      "4654/4654 [==============================] - 355s 76ms/step - loss: 0.0285 - acc: 0.9404 - val_loss: 0.0246 - val_acc: 0.9936\n",
      "Epoch 7/8\n",
      "4654/4654 [==============================] - 352s 76ms/step - loss: 0.0258 - acc: 0.9446 - val_loss: 0.0228 - val_acc: 0.5038\n",
      "Epoch 8/8\n",
      "4654/4654 [==============================] - 355s 76ms/step - loss: 0.0227 - acc: 0.9151 - val_loss: 0.0190 - val_acc: 0.9626\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "#checkpoint = keras.callbacks.ModelCheckpoint('ToxicPredict.h5', save_best_only = True)\n",
    "history = model.fit(train, epochs = 8, validation_data= valid, verbose = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c43e8c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import pickle\n",
    "with open('./first_history', 'wb') as file_pi:\n",
    "    pickle.dump(history.history, file_pi)\n",
    "\n",
    "with open('./first_history', \"rb\") as file_pi:\n",
    "    history = pickle.load(file_pi)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "80d686b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 800x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(8, 5))\n",
    "pd.DataFrame(history.history).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ed83bbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('toxic_predict.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f130517",
   "metadata": {},
   "source": [
    "### predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9e22f56f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 20   7 563 ...   0   0   0], shape=(1800,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "input_text = vectorize(\"Are you Stupid\") # Basic check.\n",
    "print(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "01a31d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-15 17:09:31.224227: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[9.8322117e-01, 1.3020018e-02, 4.5473492e-01, 2.9097337e-04,\n",
       "        8.9482903e-01, 4.8282645e-03]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.predict(np.array[input_text])\n",
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.load_model(\"toxic_predict.h5\")\n",
    "model.predict(np.expand_dims(input_text,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44616bf0",
   "metadata": {},
   "source": [
    "### Test on TestSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "35d981af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-15 17:09:36.728696: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 2297822400 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "batch_x, batch_y = test.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "044d1ba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.predict(batch_x) > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa07964a",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "69675cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Precision, Recall, CategoricalAccuracy\n",
    "\n",
    "pre = Precision()\n",
    "rec = Recall()\n",
    "acc = CategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "505cb61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in test.as_numpy_iterator():\n",
    "    x_true, y_true = batch\n",
    "    yhat = model.predict(x_true)\n",
    "    \n",
    "    y_true = y_true.flatten()\n",
    "    yhat = yhat.flatten()\n",
    "    \n",
    "    \n",
    "    pre.update_state(y_true, yhat)\n",
    "    rec.update_state(y_true, yhat)\n",
    "    acc.update_state(y_true, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c202a388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision  :0.9105458855628967\n",
      "Recall  :0.8849999904632568\n",
      "Accuracy  :0.4427710771560669\n"
     ]
    }
   ],
   "source": [
    "print(f'Precision  :{pre.result().numpy()}')\n",
    "print(f'Recall  :{rec.result().numpy()}')\n",
    "print(f'Accuracy  :{acc.result().numpy()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7834cd77",
   "metadata": {},
   "source": [
    "### USER INTERFACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "da7c05aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gradio in /home/ndip/miniconda3/envs/neural/lib/python3.8/site-packages (3.21.0)\n",
      "Requirement already satisfied: jinja2 in /home/ndip/miniconda3/envs/neural/lib/python3.8/site-packages (3.1.2)\n",
      "Requirement already satisfied: websockets>=10.0 in /home/ndip/miniconda3/envs/neural/lib/python3.8/site-packages (from gradio) (10.4)\n",
      "Requirement already satisfied: python-multipart in /home/ndip/miniconda3/envs/neural/lib/python3.8/site-packages (from gradio) (0.0.6)\n",
      "Requirement already satisfied: orjson in /home/ndip/miniconda3/envs/neural/lib/python3.8/site-packages (from gradio) (3.8.7)\n",
      "Requirement already satisfied: matplotlib in /home/ndip/miniconda3/envs/neural/lib/python3.8/site-packages (from gradio) (3.5.0)\n",
      "Requirement already satisfied: aiofiles in /home/ndip/miniconda3/envs/neural/lib/python3.8/site-packages (from gradio) (23.1.0)\n",
      "Requirement already satisfied: pillow in /home/ndip/miniconda3/envs/neural/lib/python3.8/site-packages (from gradio) (9.4.0)\n",
      "Requirement already satisfied: fsspec in /home/ndip/miniconda3/envs/neural/lib/python3.8/site-packages (from gradio) (2023.1.0)\n",
      "Requirement already satisfied: requests in /home/ndip/miniconda3/envs/neural/lib/python3.8/site-packages (from gradio) (2.28.2)\n",
      "Requirement already satisfied: altair>=4.2.0 in /home/ndip/miniconda3/envs/neural/lib/python3.8/site-packages (from gradio) (4.2.2)\n",
      "Requirement already satisfied: pandas in /home/ndip/miniconda3/envs/neural/lib/python3.8/site-packages (from gradio) (1.2.0)\n",
      "Requirement already satisfied: markupsafe in /home/ndip/miniconda3/envs/neural/lib/python3.8/site-packages (from gradio) (2.1.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.13.0 in /home/ndip/miniconda3/envs/neural/lib/python3.8/site-packages (from gradio) (0.13.2)\n",
      "Requirement already satisfied: typing-extensions in /home/ndip/miniconda3/envs/neural/lib/python3.8/site-packages (from gradio) (4.5.0)\n",
      "Requirement already satisfied: pydub in /home/ndip/miniconda3/envs/neural/lib/python3.8/site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: pyyaml in /home/ndip/miniconda3/envs/neural/lib/python3.8/site-packages (from gradio) (5.4.1)\n",
      "Requirement already satisfied: pydantic in /home/ndip/miniconda3/envs/neural/lib/python3.8/site-packages (from gradio) (1.10.6)\n",
      "Requirement already satisfied: httpx in /home/ndip/miniconda3/envs/neural/lib/python3.8/site-packages (from gradio) (0.23.3)\n",
      "Requirement already satisfied: aiohttp in /home/ndip/miniconda3/envs/neural/lib/python3.8/site-packages (from gradio) (3.8.4)\n",
      "Requirement already satisfied: fastapi in /home/ndip/miniconda3/envs/neural/lib/python3.8/site-packages (from gradio) (0.94.1)\n",
      "Requirement already satisfied: mdit-py-plugins<=0.3.3 in /home/ndip/miniconda3/envs/neural/lib/python3.8/site-packages (from gradio) (0.3.3)\n",
      "Requirement already satisfied: uvicorn in /home/ndip/miniconda3/envs/neural/lib/python3.8/site-packages (from gradio) (0.21.0)\n",
      "Requirement already satisfied: markdown-it-py[linkify]>=2.0.0 in /home/ndip/miniconda3/envs/neural/lib/python3.8/site-packages (from gradio) (2.2.0)\n",
      "Requirement already satisfied: numpy in /home/ndip/miniconda3/envs/neural/lib/python3.8/site-packages (from gradio) (1.23.5)\n",
      "Requirement already satisfied: ffmpy in /home/ndip/miniconda3/envs/neural/lib/python3.8/site-packages (from gradio) (0.3.0)\n",
      "Requirement already satisfied: entrypoints in /home/ndip/miniconda3/envs/neural/lib/python3.8/site-packages (from altair>=4.2.0->gradio) (0.4)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /home/ndip/miniconda3/envs/neural/lib/python3.8/site-packages (from altair>=4.2.0->gradio) (4.17.3)\n",
      "Requirement already satisfied: toolz in /home/ndip/miniconda3/envs/neural/lib/python3.8/site-packages (from altair>=4.2.0->gradio) (0.12.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/ndip/miniconda3/envs/neural/lib/python3.8/site-packages (from huggingface-hub>=0.13.0->gradio) (23.0)\n",
      "Requirement already satisfied: filelock in /home/ndip/miniconda3/envs/neural/lib/python3.8/site-packages (from huggingface-hub>=0.13.0->gradio) (3.9.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/ndip/miniconda3/envs/neural/lib/python3.8/site-packages (from huggingface-hub>=0.13.0->gradio) (4.64.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/ndip/miniconda3/envs/neural/lib/python3.8/site-packages (from markdown-it-py[linkify]>=2.0.0->gradio) (0.1.2)\n",
      "Requirement already satisfied: linkify-it-py<3,>=1 in /home/ndip/miniconda3/envs/neural/lib/python3.8/site-packages (from markdown-it-py[linkify]>=2.0.0->gradio) (2.0.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/ndip/miniconda3/envs/neural/lib/python3.8/site-packages (from pandas->gradio) (2022.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/ndip/miniconda3/envs/neural/lib/python3.8/site-packages (from pandas->gradio) (2.8.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/ndip/miniconda3/envs/neural/lib/python3.8/site-packages (from aiohttp->gradio) (4.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/ndip/miniconda3/envs/neural/lib/python3.8/site-packages (from aiohttp->gradio) (3.0.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ndip/miniconda3/envs/neural/lib/python3.8/site-packages (from aiohttp->gradio) (1.3.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ndip/miniconda3/envs/neural/lib/python3.8/site-packages (from aiohttp->gradio) (1.8.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ndip/miniconda3/envs/neural/lib/python3.8/site-packages (from aiohttp->gradio) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ndip/miniconda3/envs/neural/lib/python3.8/site-packages (from aiohttp->gradio) (6.0.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ndip/miniconda3/envs/neural/lib/python3.8/site-packages (from aiohttp->gradio) (22.2.0)\n",
      "Requirement already satisfied: starlette<0.27.0,>=0.26.1 in /home/ndip/miniconda3/envs/neural/lib/python3.8/site-packages (from fastapi->gradio) (0.26.1)\n",
      "Requirement already satisfied: httpcore<0.17.0,>=0.15.0 in /home/ndip/miniconda3/envs/neural/lib/python3.8/site-packages (from httpx->gradio) (0.16.3)\n",
      "Requirement already satisfied: sniffio in /home/ndip/miniconda3/envs/neural/lib/python3.8/site-packages (from httpx->gradio) (1.3.0)\n",
      "Requirement already satisfied: certifi in /home/ndip/miniconda3/envs/neural/lib/python3.8/site-packages (from httpx->gradio) (2022.12.7)\n",
      "Requirement already satisfied: rfc3986[idna2008]<2,>=1.3 in /home/ndip/miniconda3/envs/neural/lib/python3.8/site-packages (from httpx->gradio) (1.5.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ndip/miniconda3/envs/neural/lib/python3.8/site-packages (from matplotlib->gradio) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/ndip/miniconda3/envs/neural/lib/python3.8/site-packages (from matplotlib->gradio) (3.0.9)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ndip/miniconda3/envs/neural/lib/python3.8/site-packages (from matplotlib->gradio) (1.4.4)\n",
      "Requirement already satisfied: setuptools-scm>=4 in /home/ndip/miniconda3/envs/neural/lib/python3.8/site-packages (from matplotlib->gradio) (7.1.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ndip/miniconda3/envs/neural/lib/python3.8/site-packages (from matplotlib->gradio) (4.38.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ndip/miniconda3/envs/neural/lib/python3.8/site-packages (from requests->gradio) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ndip/miniconda3/envs/neural/lib/python3.8/site-packages (from requests->gradio) (1.26.14)\n",
      "Requirement already satisfied: click>=7.0 in /home/ndip/miniconda3/envs/neural/lib/python3.8/site-packages (from uvicorn->gradio) (8.1.3)\n",
      "Requirement already satisfied: h11>=0.8 in /home/ndip/miniconda3/envs/neural/lib/python3.8/site-packages (from uvicorn->gradio) (0.14.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /home/ndip/miniconda3/envs/neural/lib/python3.8/site-packages (from httpcore<0.17.0,>=0.15.0->httpx->gradio) (3.6.2)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /home/ndip/miniconda3/envs/neural/lib/python3.8/site-packages (from jsonschema>=3.0->altair>=4.2.0->gradio) (0.19.3)\n",
      "Requirement already satisfied: pkgutil-resolve-name>=1.3.10 in /home/ndip/miniconda3/envs/neural/lib/python3.8/site-packages (from jsonschema>=3.0->altair>=4.2.0->gradio) (1.3.10)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /home/ndip/miniconda3/envs/neural/lib/python3.8/site-packages (from jsonschema>=3.0->altair>=4.2.0->gradio) (5.12.0)\n",
      "Requirement already satisfied: uc-micro-py in /home/ndip/miniconda3/envs/neural/lib/python3.8/site-packages (from linkify-it-py<3,>=1->markdown-it-py[linkify]>=2.0.0->gradio) (1.0.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: six>=1.5 in /home/ndip/miniconda3/envs/neural/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas->gradio) (1.16.0)\n",
      "Requirement already satisfied: setuptools in /home/ndip/miniconda3/envs/neural/lib/python3.8/site-packages (from setuptools-scm>=4->matplotlib->gradio) (59.5.0)\n",
      "Requirement already satisfied: tomli>=1.0.0 in /home/ndip/miniconda3/envs/neural/lib/python3.8/site-packages (from setuptools-scm>=4->matplotlib->gradio) (2.0.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /home/ndip/miniconda3/envs/neural/lib/python3.8/site-packages (from importlib-resources>=1.4.0->jsonschema>=3.0->altair>=4.2.0->gradio) (3.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install gradio jinja2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "99c9127c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import gradio as gr\n",
    "\n",
    "model = tf.keras.models.load_model(\"toxic_predict.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "899e044b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False False False False False False]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['toxic', 'severe_toxic', 'obscene', 'threat', 'insult',\n",
       "       'identity_hate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# good text check\n",
    "text_check = vectorize('I will help you without a doubt')\n",
    "\n",
    "res = model.predict(np.expand_dims(text_check, 0))\n",
    "print(res > 0.5)\n",
    "\n",
    "train_data.columns[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fb4e8155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9899311  0.16045134 0.9774026  0.3687496  0.9449893  0.22822717]]\n",
      "[[ True False  True False  True False]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['toxic', 'severe_toxic', 'obscene', 'threat', 'insult',\n",
       "       'identity_hate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Toxic check\n",
    "hate_check = vectorize('I will kill you and your family! you suck')\n",
    "res = model.predict(np.expand_dims(hate_check, 0))\n",
    "print(res)\n",
    "print(res>0.5)\n",
    "train_data.columns[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9b4f60ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['toxic', 'severe_toxic', 'obscene', 'threat', 'insult',\n",
       "       'identity_hate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6b5459c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comment_interface(comment):\n",
    "    vectorize_comment = vectorize([comment])\n",
    "    results = model.predict(vectorize_comment)\n",
    "    \n",
    "    text = ''\n",
    "    for idx, col in enumerate(train_data.columns[2:]):\n",
    "        text += '{}: {}\\n'. format(col, results[0][idx]>0.5)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bd7937d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ndip/miniconda3/envs/neural/lib/python3.8/site-packages/gradio/inputs.py:27: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
      "  warnings.warn(\n",
      "/home/ndip/miniconda3/envs/neural/lib/python3.8/site-packages/gradio/deprecation.py:40: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
      "  warnings.warn(value)\n",
      "/home/ndip/miniconda3/envs/neural/lib/python3.8/site-packages/gradio/deprecation.py:40: UserWarning: `numeric` parameter is deprecated, and it has no effect\n",
      "  warnings.warn(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "Running on public URL: https://f8cfdac61a5066ca1a.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://f8cfdac61a5066ca1a.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interface = gr.Interface(fn = comment_interface,\n",
    "                        inputs = gr.inputs.Textbox(lines = 2, placeholder = 'write comment'),outputs = 'text')\n",
    "\n",
    "interface.launch(share = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283cf4aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
